# 심리 상담 대화 기반 감정 판별 모델 비교 실험 리포트 설계안

## 1. 연구 목적

본 연구는 심리 상담 대화를 기반으로 감정 상태를  
**addiction, anxiety, depression, normal**의 4개 클래스로 판별하는 모델을 학습하고,  
서로 다른 신경망 구조를 적용하여 감정 분석의 가능 수준과 한계를 검증하는 것을 목적으로 한다.

특히 순차 모델부터 Transformer 계열까지 단계적으로 비교함으로써  
모델 구조에 따른 성능 차이와 감정 판별 특성을 분석한다.

---

## 2. 문제 정의

- 입력 데이터: 심리 상담 대화 텍스트
- 출력 레이블:  
  - addiction  
  - anxiety  
  - depression  
  - normal
- 문제 유형: 다중 클래스 분류 (Multi-class Classification)

심리 상담 대화는 감정이 명시적으로 드러나지 않고 문맥 전반에 걸쳐 누적되는 특성이 있어  
장기 의존성 모델링 능력이 성능에 중요한 영향을 미친다.

---

## 3. 모델 구성 및 실험 순서

### 3.1 RNN 

**역할**
- 순차 기반 문장 분류 모델의 기본 구조
- LSTM 및 Attention 모델 성능 비교를 위한 baseline

**특징**
- 단순한 순환 구조로 이전 시점의 은닉 상태만을 활용
- 장기 의존성 학습에 취약하며, 정보 소실(vanishing gradient) 가능성 존재

**기대 결과**
- 짧은 발화나 키워드 중심 문장에서는 안정적인 성능 예상
- depression과 anxiety 간 의미적 유사성으로 혼동 빈번
- 긴 대화 문맥에서는 후반부 정보 위주로 판단하는 경향 관찰



### 3.2 Attention LSTM (LSTM + Attention)

**역할**
- 순차 기반 모델의 대표적인 확장 구조
- Attention 도입 효과를 확인하기 위한 baseline+

**특징**
- 문장 내 특정 단어 또는 발화에 집중 가능
- 긴 대화에서 장기 의존성 한계 존재

**기대 결과**
- depression과 anxiety 간 혼동 빈번
- addiction 클래스는 키워드 의존으로 비교적 구분 가능
- 대화 길이가 길어질수록 성능 저하 관찰



### 3.3 Klue-Bert (Transformer-based) 

**역할**
- 사전학습 언어모델 기반의 문장 분류 모델
- 순차 모델(RNN, LSTM) 대비 성능 상한선(upper bound) 확인을 위한 비교 모델

**특징**
- 대규모 한국어 코퍼스 기반 사전학습을 통해 풍부한 의미 표현 학습
- Self-Attention 메커니즘으로 문장 내 모든 토큰 간 관계를 병렬적으로 고려
- 문맥 의존성이 높은 감정·상태 표현에 강점

**기대 결과**
- 전반적인 분류 성능(accuracy, weighted F1)에서 가장 우수한 결과 예상
- depression과 anxiety 간 미세한 의미 차이를 비교적 안정적으로 구분
- 짧은 발화 및 긴 대화 모두에서 일관된 성능 유지
- 다만 데이터 규모가 제한적일 경우 과적합 또는 성능 변동 가능성 존재

---

## 4. 모델 선택의 이유

- 본 실험에서는 Vanilla RNN → Attention 기반 BiLSTM → KLUE-BERT 순으로 모델을 구성하였다.
이러한 순서는 단순한 성능 비교가 아니라, 모델 구조의 복잡도와 문맥 처리 능력이 점진적으로 증가하는 흐름을 반영하기 위함이다.

### Vanilla RNN: 최소 구조 기반 baseline

- Vanilla RNN은 가장 단순한 순환신경망 구조로, 이전 시점의 은닉 상태만을 활용하여 순차 정보를 처리한다.
- 본 실험에서는 RNN을 통해 입력 문장의 표면적 어휘 패턴과 단기 문맥 정보만으로 어느 수준까지 분류가 가능한지 확인하고자 하였다.
- 이를 통해 이후 모델에서 관찰되는 성능 향상이 단순한 파라미터 증가가 아닌, 구조적 개선에 기인한 것인지를 판단할 수 있다.

### Attention 기반 BiLSTM: 순차 모델의 확장
- LSTM은 Vanilla RNN 대비 장기 의존성 학습이 가능하며, 양방향 구조(Bidirectional)를 통해 문장의 전후 문맥을 동시에 고려할 수 있다.
- 여기에 Attention 메커니즘을 결합함으로써, 모델이 전체 문장을 동일하게 처리하는 것이 아니라 분류에 기여하는 핵심 단어 또는 발화 구간에 선택적으로 집중할 수 있도록 설계하였다.
- 이를 통해 본 실험에서는 단순한 순차 처리의 한계를 선택적 문맥 집중이 어느 정도 보완할 수 있는지를 평가하고자 하였다.

### KLUE-BERT: 사전학습 기반 상한선 모델
- KLUE-BERT는 대규모 한국어 코퍼스를 기반으로 사전학습된 Transformer 모델로, Self-Attention을 통해 문장 내 모든 토큰 간 관계를 병렬적으로 모델링할 수 있다.
- 본 실험에서는 KLUE-BERT를 순차 모델 계열(RNN, LSTM)의 성능 한계를 확인하고
- 사전학습 언어모델이 도메인 특화 데이터에서 어느 정도의 성능 이점을 제공하는지 비교하기 위한
상한선(upper bound) 모델로 사용하였다.
- 이를 통해, 단순한 모델 복잡도 증가가 아닌
사전학습 여부와 문맥 표현력 차이가 분류 성능에 미치는 영향을 명확히 분석할 수 있다.


---

## 5. 데이터 설계 고려 사항

### 데이터 설계 고려 사항
- 본 실험에서는 모델 성능 비교뿐만 아니라, 데이터 구성 방식이 결과 해석에 미치는 영향을 함께 고려하였다.
- 이를 위해 다음과 같은 데이터 설계 요소를 사전에 검토하였다.

### 발화 단위 정의
- 본 데이터는 상담 대화로 구성되어 있어, 단일 발화(utterance) 단위와 세션 단위 중 어떤 수준에서 모델링할지에 따라 문맥 정보의 범위가 달라질 수 있다.
- 단일 발화 단위는 모델이 국소적인 언어 패턴에 집중하도록 유도하는 반면, 세션 단위는 보다 풍부한 문맥 정보를 제공할 수 있으나 입력 길이 증가로 인한 학습 난이도 상승 가능성이 존재한다.
- 본 실험에서는 모델 간 공정한 비교를 위해 발화 단위 기준의 입력을 기본으로 사용하되, 문맥 길이에 따른 성능 변화는 결과 해석 시 함께 고려한다.

### 클래스 불균형 문제
- 실제 상담 데이터 특성상, addiction 및 depression 클래스가 상대적으로 많이 포함될 가능성이 있다.
- 이러한 클래스 불균형은 accuracy 지표를 과대평가할 수 있으므로, macro F1-score를 주요 평가 지표로 사용하여 소수 클래스에 대한 분류 성능을 함께 평가한다.
- 또한 confusion matrix 및 클래스별 precision/recall 분석을 통해 특정 클래스에 대한 과도한 편향 여부를 확인한다.

### 데이터 익명화 및 윤리적 고려 사항
- 모든 데이터는 개인을 식별할 수 있는 정보가 제거된 상태로 처리되었으며, 모델 학습 및 결과 분석 과정에서 개인 식별 가능 정보는 사용하지 않는다.
- 본 실험은 자동화된 예측 결과를 진단이나 판단의 근거로 사용하지 않으며, 연구 목적의 분석 및 모델 비교에 한정하여 수행된다.
- 민감한 정신건강 관련 데이터를 다루는 특성을 고려하여, 결과 해석 시 모델의 한계와 오분류 가능성을 명확히 인지하고 기술한다.


---

## 6. 평가 지표

단순 accuracy 외에 다음 지표를 함께 사용한다.

- Macro F1-score (핵심 지표)
- Class-wise Precision / Recall
- Confusion Matrix

특히 다음 오분류 패턴을 중점 분석한다.

- anxiety ↔ depression
- normal ↔ anxiety

---


## 7. 결과 해석 방향

본 연구는 다음과 같은 결론 구조를 목표로 한다.

- addiction, depression과 같은 중증 감정 상태는 비교적 높은 분별력을 보임
- anxiety와 normal은 경계가 모호하며 문맥 이해 능력이 성능에 큰 영향을 미침
- Transformer Encoder 계열에서 전반적인 성능 개선이 관찰됨
- 감정 상태는 단일 문장보다 대화 전반의 누적 맥락에서 더 잘 포착됨

---


## 8. 결론

Attention RNN에서 Transformer Encoder, Transformer Decoder로 이어지는 모델 비교 실험은  
감정 분석 성능의 구조적 차이를 설명하기에 적절한 흐름을 제공한다.

특히 Transformer Encoder를 중심축으로 설정할 경우  
심리 상담 대화 기반 감정 판별이 어느 수준까지 가능한지  
정량적·정성적으로 명확히 제시할 수 있다.

